---
title: "FCAI Presentation Talk"
subtitle: '2024-05-10'
bibliography: presentation.bib
---

<!-- https://github.com/quarto-dev/quarto-cli/discussions/4572 -->
```{=html}
<style>
.semi-transparent {
  opacity: 0.3;
}
</style> 
```         
   
<br> 
 

### Outline


:one: Introducing Myself

:two: Research I : Static Representations

:three: Research II : Directed Link Prediction

<!-- :two: Current Work & Future Directions -->

:four: Doctoral Degree
  
<!-- :three: Deep Directed Graph Generative Models 

:four: Static Representations -->

<!-- :two: Transaction Networks -->



# Introducing Myself

1. Introducing Myself





<!-- ## [Introducing Myself]{.semi-transparent} {.smaller}

1. Introducing Myself:

    1.1 Past Education

    1.2 M.Sc. Thesis -->


## Past Education {.smaller .scrollable}

**B.Sc.** (Physics, 110L, University of Turin). Thesis: 

- AeroSpace Software Engineering - MCS @[ALTEC S.p.A.](https://www.altecspace.it/);
- Scientific/Experimental - Feasibility (Data) Analysis for [MINI-EUSO](https://www.jemeuso.org/missions/mini-euso/) Mission;
- [Slides](http://personalpages.to.infn.it/~bertaina/tesi-scaricate/Moroni-laurea2.pdf).

. . .

**M.Sc.**:

- Physics of Complex Systems, 110L University of Turin:

    - **Background**: Physics (Stat. Mech., SDEs, QFT,...), Complex Systems (ABM, Comp. Soc. Sci. ([practice review](https://github.com/ClaudMor/Algorithmic_Bias_in_Echo_Chamber_Formation/blob/main/Algorithmic_Bias_In_Echo_Camber_Formation.pdf)), Network Theory, Comp. Neur. );

    - **Machine/Deep Learning**: NLP ([ensemble models](https://github.com/ClaudMor/Reddit_Text_Classification), [large models](https://github.com/ClaudMor/IMDb_Sentiment_Analysis_BERT)), [Computer Vision](https://github.com/ClaudMor/Plant_Disease_Classification_CNN);

    - Thesis at [CENTAI](https://centai.eu/home).    

. . .

- Co-Founded **Interdiscipliary Physics Team** ([Twitter](https://twitter.com/In_Phy_T), [LinkedIn](https://www.linkedin.com/company/interdisciplinary-physics-team-inphyt/?viewAsMember=true), [GitHub](https://github.com/InPhyT)):

    - @Moroni2023 ([MIT Talk](https://youtu.be/Q2PwKQCkZJ4?si=Qj3QrHy7NmhQXllW), [Fields Institute Talk](https://youtu.be/hB8Vrwkwax0?si=R0fNmrtFxNXQ15fw))

    - [COVID-19_Piedmont](https://github.com/UniTo-SEPI)

    - [COVID-19 Integrated Surveillance Data in Italy](https://github.com/InPhyT/COVID19-Italy-Integrated-Surveillance-Data)

    - [UnrollingAverages.jl](https://github.com/InPhyT/UnrollingAverages.jl)

    - [ICD_GEMs.jl](https://github.com/UniTo-SEPI/ICD_GEMs.jl)

    - [Neuronal Dynamics](https://claudmor.github.io/Presentations/NeuronalDynamics/#/title-slide)

. . . 

- More Extracurricular:

    - Deep Architectures for Stock Index Tracking (Sella Bank-UniUPO, [link](https://of.uniupo.it/syllabus/didattica.php/en/2023/1407#222400))

    - [IPSP2023](https://event.unitn.it/ipsp2023/) (UniTrento)

    - ...

. . .

- Currently employed as Data Scientist Intern at [ORS](https://ors.ai/).

## Research I : Static Representations

1. Transaction Networks

2. (Anti-)Money Laundering

3. Graph Neural Networks

4. Proposed Static Representation 

5. Results

 
## Transaction Networks {.scrollable}


![](images/transaction_network.PNG){fig-align="center"}


<!-- 
## Transaction Networks {.smaller}

:::: {.columns}

::: {.column width="25%"}

Account Features

![Courtesy of @JENSEN2023119037](images/accounts_features.PNG){fig-align="left" height=475}


:::
::: {.column width="75%"}

::: {.fragment}
Transaction Features


![Courtesy of @altman2023realistic](images/transactions_features.PNG){fig-align="center" height=200}

:::

:::

:::: -->





## (Anti-)Money Laundering


<!-- ::: {.center_vert} -->

::: {.absolute top=40%}

![Courtesy of @altman2023realistic](images/AMLworld_L1_Laundering_Patterns.PNG){fig-align="center" width=5000} 

:::
<!-- ::: -->

<!-- fig-align="center" Courtesy of @altman2023realistic -->

<!-- . . .

![Courtesy of @TemporalMotifs_Leskovec2017](images/temporal_motif.PNG){fig-align="center"}

. . . -->



## (Anti-)Money Laundering {.smaller}


::: footer
Introduction
:::

![Courtesy of @Saxena2022_Rabobank](images/transaction_network_saxena.PNG){fig-align="center"}


. . .

::: {.center_horiz}

$\implies$ **Neural** Subgraph Matching!

:::



## Graph Neural Networks {.smaller .scrollable}




::: {.fragment}
Based on a *spectrally-justifiable* aggregation strategy:

:::

<!-- ::: {.r-stack} -->
<!-- 
::: {.fragment .fade-in-then-out}
![](images/gnn_1.png){fig-align="center" width=400 height=285}

$$ $$
:::

::: {.fragment .fade-in-then-out}
![](images/gnn_2.png){fig-align="center" width=400 height=285}

$$ $$
:::


::: {.fragment .fade-in-then-out}
![](images/gnn_3.png){fig-align="center" width=400 height=285}

$$\vec{h}_v^{(1)} = f_{\Theta_0}(\vec{h}_v^{(0)}, \{ \vec{h}_u^{(0)} | u \in N(v)\})$$

:::


::: {.fragment .fade-in-then-out}
![](images/gnn_5.png){fig-align="center" width=400 height=285}

$$\vec{h}_v^{(1)} = f_{\Theta_0}(\vec{h}_v^{(0)}, \{ \vec{h}_u^{(0)} | u \in N(v)\})$$

::: -->


::: {.fragment .fade-in}
![](images/gnn_6.png){fig-align="center" width=400 height=285}

$$\vec{h}_v^{(k+1)} = f_{\Theta_k}(\vec{h}_v^{(k)}, \{ \vec{h}_u^{(k)} | u \in N(v)\})$$

:::

<!-- ::: -->


::: {.fragment}
**DISADVANTAGES**:
:::



::: {.fragment}
- Require *Static Network*;
:::


::: {.fragment}
**ADVANTAGES**:
:::
<!-- 
::: {.fragment}
- *Principled*;
:::

::: {.fragment}
- *Easy* and *cheap* to use;
:::
::: {.fragment}
- *Real-world*, efficacy^[@zhong2024evolmpnn, @Bloemheuvel2022, @egressy2024provably].
::: -->



::: {.fragment}
- *(Static) Subgraph Matching* already developed^[@rex2020neural, @Fey2020Deep];
:::





## Previous Works


:::: {.columns}

::: {.column width="48%"}

![](images/SR_original.PNG){fig-align="center"}

:::


::: {.column width="2%"}
::: {.center_vert}
$$\longrightarrow$$
:::

:::


::: {.column width="2%"}

:::


::: {.column width="48%"}

![](images/SR_DLGE.PNG){fig-align="center" height=200}


![Courtesy of @oetterhsagen2020](images/SR_SEK.PNG){fig-align="center" height=200}

:::
::::


## Proposed Static Representation 


 

:::: {.columns style='display: flex !important; height: 90%;' }

::: {.column width="49%"}

![](images/triangle_temporal.png){width=300 .absolute top=25%}

 <!-- fig-align="center" height=300 -->

:::


::: {.column width="2%"}

::: {.absolute top=40% left=300}
$\longrightarrow$
:::

:::
<!-- ![](images/arrow.png){fig-align="center" .absolute top=25%} -->
 
::: {.column width="49%"}

![](images/triangle_sr.png){height=400}


<!-- ![Courtesy of @oetterhsagen2020](images/SR_SEK.PNG){fig-align="center" height=200} -->

:::
::::


## Results

Node ranking task on [TGBN-Trade](https://tgb.complexdatalab.com/docs/nodeprop/#tgbn-trade):

:::{.center_horiz .center_vert}

| Model     | NDCG@10 |
| --------- | ------- |
| Ours      | 0.549   |
| DygFormer | 0.388   |
| TGN       | 0.374   |

:::




## Research II : Directed Link Prediction

<!-- 1. Introduction

2. Autoencoders -->

1. Related Works

2. Proposed Framework: MFDLP

<!-- 2. Naive Approach -->

<!-- 
## Introduction




:::: {.columns}

::: {.column width="48%"}


![](images/gnn_1.png){fig-align="center"}

:::


::: {.column width="2%"}
::: {.center_vert}
$$\longrightarrow$$
:::

:::


::: {.column width="2%"}

:::


::: {.column width="48%"}

![](images/generation.PNG){fig-align="center"}
:::
::::


:::{.fragment .center_horiz}

$\iff$ (Directed Stochastic) **Link Prediction**!
:::



## Autoencoders

![](images/AE.png){fig-align="center"}



## Variational Autoencoders


![](images/VAE.png){fig-align="center"}


## Variational Graph Autoencoders


![](images/VGAE.png){fig-align="center"} -->


  



## Related Works

![](images/related_works_whole_graph.png){fig-align="center"}


## Related Works

![](images/rw_dlp_training.png){fig-align="center"}

## Related Works

![](images/rw_dlp_training_green.png){fig-align="center"}


## Related Works

![](images/rw_dlp_training_green_red.png){fig-align="center"}

. . .

$$\mathcal{L}(\Theta) = \sum\limits_{e \in {E_{s + n}}} y_e\ln(\hat{p}_{\Theta}(e)) + (1-y_e)\ln(1-\hat{p}_{\Theta}(e))$$






## Related Works {.smaller .scrollable}


:::: {.columns}

::: {.column width=27%}

Training Set


![](images/rw_dlp_training_green_red.png){fig-align="center"}


:::


::: {.column width=3%}



![](images/vert_sep.png){fig-align="center" height=300 width=20}



:::


::: {.column width=70%}

Test Set

::: {.fragment}

![](images/rw_dlp_test_general.png){fig-align="center" height=250}

:::

:::

::::


. . .

Undirected Model:

| Metric   | Performance       |
| -------- | ----------------- |
| ROC -AUC | 0.829 $\pm$ 0.002 |
| hits@20  | 0.59 $\pm$ 0.01   |
| AP-AUC   | 0.872 $\pm$ 0.001 |


. . .

**WHY**? Directionality never really tested.




## Related Works {.smaller .scrollable}


Training Set


![](images/rw_dlp_training_green_red.png){fig-align="center"  height=150}


Test Set(s)^[@Salha2019, @zhang2021magnet]

:::: {.columns}

::: {.column width=31%}
![General](images/rw_dlp_test_general.png){fig-align="center"}
:::


::: {.column width=2%}
:::{.fragment}
![](images/vert_sep.png){fig-align="center" height=200}
:::
:::




::: {.column width=32%}
:::{.fragment}


![Directional](images/rw_dlp_test_directional.png){fig-align="center"}

:::
:::


::: {.column width=2%}
:::{.fragment}
![](images/vert_sep.png){fig-align="center" height=200}
:::
:::



::: {.column width=32%}
:::{.fragment}
![Bdirectional](images/rw_dlp_test_bidirectional.png){fig-align="center"}
:::
:::

::::

## Related Works

![Courtesy of @Salha2019](images/salha_results_cora.PNG){fig-align="center"}


. . .


::: {.center_horiz .absolute top=70%}
$\implies$ Find a **UNIQUE** model for **ALL** three sub-tasks.

:::
<!-- 
## Naive Approach

:::: {.columns}

::: {.column width="50%"}

General to Directional

|           | gravity_gae   |
|:----------|:--------------|
| AUC       | 0.6 +- 0.0    |
| F1        | 0.6 +- 0.0    |
| hitsk     | 0.1 +- 0.0    |
| AP        | 0.6 +- 0.0    |

:::

::: {.column width="50%"}

Directional to General

|           | gravity_gae   |
|:----------|:--------------|
| AUC       | 0.4 +- 0.0    |
| F1        | 0.06 +- 0.0   |
| hitsk     | 0.02 +- 0.0   |
| AP        | 0.4 +- 0.0    |


:::

::::

. . .


::: { .absolute top=80% }
$\implies$ **Doesn't work**!
:::


## Naive Approach {.smaller .scrollable}
 
::: {.center_horiz}
**WHY**?
:::



:::: {.columns}




::: {.column width=47%}


::: {.absolute top=50% left=0}

Training Set

![](images/rw_dlp_training_green_red.png){fig-align="left"}


:::
:::

::: {.column width=3%}


![](images/vert_sep.png){fig-align="center" height=875 width=20}

:::


::: {.column width=50%}

Test Set(s)


![General](images/rw_dlp_test_general.png){fig-align="center" height=250}




![](images/plus.png){fig-align="center" height=50}


![Directional](images/rw_dlp_test_directional.png){fig-align="center" height=250}

:::

:::: -->

## Proposed Framework: MFDLP {.smaller}


**SOLUTION**. Map DLP to 4-class Edge Classification:

- Positive Unidirectional (*PU*)
- Negative Unidirectional (*NU*)
- Positive Bidirectional (*PB*)
- Negative Bidirectional (*NB*)

. . .

And then **balance** the loss:

$$\mathcal{L}(\Theta) = - \sum\limits_{e \in E_{s+n}} w_{y_e} \ln(\hat{p}_{\Theta}(e))$$

. . .
 
Where:

$$w_{y_e} = \frac{n_{x}}{n_{y_e}}$$


<!-- ## Proposed Framework: MFDLP

$$\mathcal{L}(\Theta) = - \sum\limits_{e \in E_{s+n}} w_{y_e} \ln(\hat{p}_{\Theta}(e))$$

. . .
 
Where:

$$w_{y_e} = \frac{n_{x}}{n_{y_e}}$$ -->

  

  
## Proposed Framework: MFDLP {.smaller}


| Model       | General       | Directional   | Bidirectional |
|:---------------:|:-----------------:|:-----------------:|:-----------------:|
| G-GAE + MFDLP   | 81.5 $\pm$ 0.2    | 76.3 $\pm$ 0.2    | 81 $\pm$ 1        |
| G-GAE           | 79.4 $\pm$ 0.7    | 55 $\pm$ 4        | 63 $\pm$ 6        |
| ST-GAE + MFDLP  | 74 $\pm$ 4        | 76 $\pm$ 2        | 83 $\pm$ 3        |
| ST-GAE          | 82.4 $\pm$ 0.7    | 57 $\pm$ 1        | 70 $\pm$ 5        |
| MIX + MFDLP     | 78 $\pm$ 4        | 74 $\pm$ 2        | 84 $\pm$ 1        |
| MIX             | 82.4 $\pm$ 0.7    | 57 $\pm$ 1        | 70 $\pm$ 5        |
| MIXDIST + MFDLP | 0.807 $\pm$ 0.008 | 0.744 $\pm$ 0.006 | 0.82 $\pm$ 0.01   |
| MIXDIST         | 0.786 $\pm$ 0.008 | 0.502 $\pm$ 0.002 | 0.71 $\pm$ 0.03   |
| MIXNORM + MFDLP | 0.796 $\pm$ 0.005 | 0.775 $\pm$ 0.002 | 0.79 $\pm$ 0.005  |
| MIXNORM         | 0.83 $\pm$ 0.01   | 0.539 $\pm$ 0.005 | 0.75 $\pm$ 0.02   |
| MLP + MFDLP     | 0.623 $\pm$ 0.007 | 0.78 $\pm$ 0.01   | 0.81 $\pm$ 0.01   |
| MLP             | 0.654 $\pm$ 0.004 | 0.838 $\pm$ 0.004 | 0.798 $\pm$ 0.008 |

: {.table-striped}



<!-- 
```{=latex}
\begin{table}[tbp]
  \rowcolors{1}{}{lightgray}
  \begin{tabular}{|l|c|c|c|}
  \toprule
    Model & General & Directional & Bidirectional \\
  \midrule
  G-GAE + MFDLP &  81.5 $\pm$ 0.2 & 76.3 $\pm$ 0.2 &  81 $\pm$ 1 \\
  G-GAE & 79.4 $\pm$ 0.7 & 55 $\pm$ 4 & 63 $\pm$ 6 \\
  \midrule
  ST-GAE + MFDLP & 74 $\pm$ 4 & 76 $\pm$ 2 & 83 $\pm$ 3 \\
  ST-GAE & 82.4 $\pm$ 0.7 & 57 $\pm$ 1 & 70 $\pm$ 5 \\
  \midrule
  MIX + MFDLP & 78 $\pm$ 4 & 74 $\pm$ 2 &  84 $\pm$ 1 \\
  MIX & 82.4 $\pm$ 0.7 &  57 $\pm$ 1 & 70 $\pm$ 5 \\
  \midrule
  MIXDIST + MFDLP & 0.807 $\pm$ 0.008 &  0.744 $\pm$ 0.006 & 0.82 $\pm$ 0.01 \\
  MIXDIST & 0.786 $\pm$ 0.008 & 0.502 $\pm$ 0.002 & 0.71 $\pm$ 0.03  \\
  \midrule
  MIXNORM + MFDLP & 0.796 $\pm$ 0.005  & 0.775 $\pm$ 0.002  & 0.79 $\pm$ 0.005 \\
  MIXNORM & 0.83 $\pm$ 0.01  & 0.539 $\pm$ 0.005  & 0.75 $\pm$ 0.02 \\
  \midrule
  MLP + MFDLP & 0.623 $\pm$ 0.007 & 0.78 $\pm$ 0.01 &  0.81 $\pm$ 0.01 \\
  MLP & 0.654 $\pm$ 0.004 & 0.838 $\pm$ 0.004 & 0.798 $\pm$ 0.008\\
  \bottomrule
  \end{tabular}
\end{table}
``` -->
  <!-- \midrule
  MLP + MFDLP & 0.623 $\pm$ 0.007 & 0.78 $\pm$ 0.01 &  0.81 $\pm$ 0.01 \\
  MLP & 0.654 $\pm$ 0.004 & 0.838 $\pm$ 0.004 & 0.798 $\pm$ 0.008\\ -->

<!-- \begin{table}[tbp]
    % \begin{adjustwidth}{-3cm}{-3cm}
    \label{tab-results_table_cora_ap}
    \vskip 0.15in
    \begin{center}
    \begin{small}
    \begin{sc}
    \resizebox{\linewidth}{!}{
    \begin{tabular}{|l|c|c|c|}
    \toprule
     Model & General & Directional & Bidirectional \\
    \midrule
    GAE & 82 $\pm$ 2 & 50 $\pm$ 0  &  64 $\pm$ 5 \\
    \midrule
    G-GAE + MFDLP &  84.8 $\pm$ 0.4  & 75.2 $\pm$ 0.2 & 82 $\pm$ 1 \\
    G-GAE & 86.0 $\pm$ 0.5 & 55 $\pm$ 4  & 58 $\pm$ 7 \\
    \midrule
    ST-GAE + MFDLP & 76 $\pm$ 5  & 77 $\pm$ 1 & 85 $\pm$ 2 \\
    ST-GAE & 85 $\pm$ 2 & 62 $\pm$ 1 & 73 $\pm$ 4 \\
    \midrule
    MIX + MFDLP & 77 $\pm$ 2 &  75 $\pm$ 2 & 84 $\pm$ 1 \\
    MIX &  85 $\pm$ 2 & 62 $\pm$ 1 & 73 $\pm$ 4 \\
    \midrule
    MIXDIST + MFDLP & 0.83 $\pm$ 0.01 & 0.757 $\pm$ 0.005 & 0.834 $\pm$ 0.008 \\
    MIXDIST & 0.852 $\pm$ 0.006 & 0.505 $\pm$ 0.002 & 0.73 $\pm$ 0.03 \\
    \midrule
    MIXNORM + MFDLP & 0.837 $\pm$ 0.006    & 0.783 $\pm$ 0.003  & 0.81 $\pm$ 0.005 \\
    MIXNORM & 0.874 $\pm$ 0.008  &  0.57 $\pm$ 0.01 & 0.79 $\pm$ 0.02 \\
    \midrule
    MLP + MFDLP & 0.635 $\pm$ 0.007 & 0.795 $\pm$ 0.008 & 0.83 $\pm$ 0.01 \\
    MLP &  0.643 $\pm$ 0.003 & 0.831 $\pm$ 0.003 & 0.825 $\pm$ 0.007\\
    \bottomrule
    \end{tabular}
    }
    \end{sc}
    \end{small}
    \end{center}
    \vskip -0.1in
    \caption{AP-AUC test scores of various AE models on Cora Dataset, trained both naively (random train/val/test split and balancing positives and negatives) and with our framework. Scores are in \%.}
\end{table}
``` -->


## Proposed Framework: MFDLP {.smaller}


![](images/MFDLP_DvG_circles.png){fig-align="center"}

## Proposed Framework: MFDLP {.smaller}


![](images/MFDLP_BvG_circles.png){fig-align="center"}

## Proposed Framework: MFDLP {.smaller}


![](images/MFDLP_BvD_circles.png){fig-align="center"}


## Future Developments

- Try **Subgraph Matching** task with **Static Representations**;

. . .

- Try generation with VGAE and compare **degree distributions**;

. . .

- Try Graph Diffusion (@vignac2023digress) for **graph generation**.


## Doctoral Degree {.smaller}

**TOPICS**:

- Graph Machine Learning;

. . .

- Physics-Informed Neural Networks;

. . .

- Accept Suggestions (e.g. applications to Computer Vision);

. . .

**SKILLS**:

- Become **independent** researcher;

. . .

- Gain **expertise** on the selected topic;

. . .

**GOALS**:

- Develop **impactful** ideas;

. . .

- Build **academic/industry** network.




# Thanks :pray:


<!-- IT-AML: link prediction 3 tasks e trova il train set che faccia bene almeno le prime 2 -->

<!-- # Extras

1. Variational Graph Autoencoders



## Variational Graph Autoencoders {.smaller}



![](images/VGAE_formulae.png){fig-align="center"}

::: {.r-stack} 

::: {.fragment .fade-in-then-out} 
$$\hat{p}(e_{ij}) = \text{Model}(\vec{h}^{(0)}_i, \vec{h}^{(0)}_j)$$
:::

::: {.fragment .fade-in-then-out}
$$\hat{p}(e_{ij}) = \text{Model}(\vec{h}^{(0)}_i, \vec{h}^{(0)}_j) = \text{Dec}(\text{Enc}(\vec{h}^{(0)}_i), \text{Enc}(\vec{h}^{(0)}_j))$$
:::

::: {.fragment .fade-in-then-out}
$$\hat{p}(e_{ij}) = \text{Model}(\vec{h}^{(0)}_i, \vec{h}^{(0)}_j) = \text{Dec}(\text{Enc}(\vec{h}^{(0)}_i), \text{Enc}(\vec{h}^{(0)}_j)) = \text{Dec}(\vec{h}^{(L)}_i, \vec{h}^{(L)}_j)$$
:::


::: {.fragment .fade-in}
\begin{equation}
\begin{split}
\hat{p}(e_{ij}) = \text{Model}(\vec{h}^{(0)}_i, \vec{h}^{(0)}_j) &= \text{Dec}(\text{Enc}(\vec{h}^{(0)}_i), \text{Enc}(\vec{h}^{(0)}_j)) = \text{Dec}(\vec{h}^{(L)}_i, \vec{h}^{(L)}_j) \\ &=
\begin{cases}
\vec{h}^{(L)}_i \cdot \vec{h}^{(L)}_j \\
\vec{h}^{(L)}_i[:l/2] \cdot \vec{h}^{(L)}_j[l/2:] 
\end{cases}
\end{split}
\end{equation}
:::

::: -->



# References